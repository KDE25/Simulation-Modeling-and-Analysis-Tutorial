{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMzF9wiFkHdeTLXm3P71B/C"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Regularization (L1, L2)"],"metadata":{"id":"rZT4KCGqdMGA"}},{"cell_type":"markdown","source":["## Regularization - Lasso"],"metadata":{"id":"KvE_z71xd2uk"}},{"cell_type":"markdown","source":["Lets see how to implement this using python:\n","\n","\n","* X, y = make_regression(n_samples=100, n_features=5, noise=0.1, random_state=42): Generates a regression dataset with 100 samples, 5 features and some noise.\n","* X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42): Splits the data into 80% training and 20% testing sets.\n","* lasso = Lasso(alpha=0.1): Creates a Lasso regression model with regularization strength alpha set to 0.1."],"metadata":{"id":"ytZ1YTC8lf4F"}},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KQDuSHv0cW6x","executionInfo":{"status":"ok","timestamp":1770292653939,"user_tz":-420,"elapsed":3486,"user":{"displayName":"RD Prastowo","userId":"02625078348602365406"}},"outputId":"5dbc304f-d111-4628-b39c-f55f4554ceea"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mean Squared Error: 0.06362439921332456\n","Coefficients: [60.50305581 98.52475354 64.3929265  56.96061238 35.52928502]\n"]}],"source":["from sklearn.linear_model import Lasso\n","from sklearn.model_selection import train_test_split\n","from sklearn.datasets import make_regression\n","from sklearn.metrics import mean_squared_error\n","\n","X, y = make_regression(n_samples=100, n_features=5, noise=0.1, random_state=42)\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","lasso = Lasso(alpha=0.1)\n","lasso.fit(X_train, y_train)\n","\n","y_pred = lasso.predict(X_test)\n","\n","mse = mean_squared_error(y_test, y_pred)\n","print(f\"Mean Squared Error: {mse}\")\n","\n","print(\"Coefficients:\", lasso.coef_)"]},{"cell_type":"markdown","source":["The output shows the model's prediction error and the importance of features with some coefficients reduced to zero due to L1 regularization."],"metadata":{"id":"X7xPbNelduvk"}},{"cell_type":"markdown","source":["## Regularization - Ridge"],"metadata":{"id":"CeLEQjbBd-V9"}},{"cell_type":"markdown","source":["Lets see how to implement this using python:\n","\n","ridge = Ridge(alpha=1.0): Creates a Ridge regression model with regularization strength alpha set to 1.0."],"metadata":{"id":"OlzwbEiul5QO"}},{"cell_type":"code","source":["from sklearn.linear_model import Ridge\n","from sklearn.datasets import make_regression\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import mean_squared_error\n","\n","X, y = make_regression(n_samples=100, n_features=5, noise=0.1, random_state=42)\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","ridge = Ridge(alpha=1.0)\n","ridge.fit(X_train, y_train)\n","y_pred = ridge.predict(X_test)\n","\n","mse = mean_squared_error(y_test, y_pred)\n","print(\"Mean Squared Error:\", mse)\n","print(\"Coefficients:\", ridge.coef_)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Yp5TCET-dJzi","executionInfo":{"status":"ok","timestamp":1770292695407,"user_tz":-420,"elapsed":46,"user":{"displayName":"RD Prastowo","userId":"02625078348602365406"}},"outputId":"64f64254-b7ed-414b-9a47-ca93e7040d6d"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mean Squared Error: 4.114050771972589\n","Coefficients: [59.87954432 97.15091098 63.24364738 56.31999433 35.34591136]\n"]}]},{"cell_type":"markdown","source":["The output shows the MSE showing model performance. Lower MSE means better accuracy. The coefficients reflect the regularized feature weights."],"metadata":{"id":"8vUzFO29dpwH"}},{"cell_type":"markdown","source":["## Elastic Net Regression"],"metadata":{"id":"aoYmlDIVlOSd"}},{"cell_type":"markdown","source":["Lets see how to implement this using python:\n","\n","model = ElasticNet(alpha=1.0, l1_ratio=0.5) : Creates an Elastic Net model with regularization strength alpha=1.0 and L1/L2 mixing ratio 0.5."],"metadata":{"id":"WYz3o9tOmL6o"}},{"cell_type":"code","source":["from sklearn.linear_model import ElasticNet\n","from sklearn.datasets import make_regression\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import mean_squared_error\n","\n","X, y = make_regression(n_samples=100, n_features=10, noise=0.1, random_state=42)\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","model = ElasticNet(alpha=1.0, l1_ratio=0.5)\n","model.fit(X_train, y_train)\n","\n","y_pred = model.predict(X_test)\n","mse = mean_squared_error(y_test, y_pred)\n","\n","print(\"Mean Squared Error:\", mse)\n","print(\"Coefficients:\", model.coef_)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jFCpmD5ClNrC","executionInfo":{"status":"ok","timestamp":1770292703397,"user_tz":-420,"elapsed":16,"user":{"displayName":"RD Prastowo","userId":"02625078348602365406"}},"outputId":"78d90df9-9171-4d09-bf73-ad044db48158"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Mean Squared Error: 7785.886176938014\n","Coefficients: [16.84528938 31.77080959  4.05901996 40.18486737 57.25856154 45.81463318\n"," 58.97979422 -0.          3.82816854 41.1096051 ]\n"]}]},{"cell_type":"markdown","source":["The output shows MSE which measures how far off predictions are from actual values (lower is better) and coefficients show feature importance"],"metadata":{"id":"zmM8OWs8lZPe"}},{"cell_type":"markdown","source":["# Grid Search & Random Search"],"metadata":{"id":"8bdnTKes6yct"}},{"cell_type":"markdown","source":["## GridSearchCV"],"metadata":{"id":"00O4GNRFeBrB"}},{"cell_type":"markdown","source":["The following code illustrates how to use GridSearchCV .\n","\n","In this below code:\n","* We generate sample data using make_classification.\n","* We define a range of C values using logarithmic scale.\n","* GridSearchCV tries all combinations from param_grid and uses 5-fold cross-validation.\n","* It returns the best hyperparameter (C) and its corresponding validation score"],"metadata":{"id":"skZ2Ny9Zek-f"}},{"cell_type":"code","source":["from sklearn.linear_model import LogisticRegression\n","from sklearn.model_selection import GridSearchCV\n","import numpy as np\n","from sklearn.datasets import make_classification\n","\n","X, y = make_classification(\n","    n_samples=1000, n_features=20, n_informative=10, n_classes=2, random_state=42)\n","\n","c_space = np.logspace(-5, 8, 15)\n","param_grid = {'C': c_space}\n","\n","logreg = LogisticRegression()\n","\n","logreg_cv = GridSearchCV(logreg, param_grid, cv=5)\n","\n","logreg_cv.fit(X, y)\n","\n","print(\"Tuned Logistic Regression Parameters: {}\".format(logreg_cv.best_params_))\n","print(\"Best score is {}\".format(logreg_cv.best_score_))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MQCmNW-Sd0Fs","executionInfo":{"status":"ok","timestamp":1770292709544,"user_tz":-420,"elapsed":850,"user":{"displayName":"RD Prastowo","userId":"02625078348602365406"}},"outputId":"7d555a98-d405-4f1c-8a11-2b7e788fb9a2"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Tuned Logistic Regression Parameters: {'C': np.float64(0.006105402296585327)}\n","Best score is 0.853\n"]}]},{"cell_type":"markdown","source":["## RandomSearchCV"],"metadata":{"id":"KzftH0U4eIqC"}},{"cell_type":"markdown","source":["The following code illustrates how to use RandomizedSearchCV.\n","\n","In this example:\n","\n","* We define a range of values for each hyperparameter e.g, max_depth, min_samples_leaf etc.\n","* Random combinations are picked and evaluated using 5-fold cross-validation.\n","* The best combination and score are printed."],"metadata":{"id":"CWUBgKn3eQu3"}},{"cell_type":"code","source":["import numpy as np\n","from sklearn.datasets import make_classification\n","\n","X, y = make_classification(n_samples=1000, n_features=20, n_informative=10, n_classes=2, random_state=42)\n","\n","from scipy.stats import randint\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.model_selection import RandomizedSearchCV\n","\n","param_dist = {\n","    \"max_depth\": [3, None],\n","    \"max_features\": randint(1, 9),\n","    \"min_samples_leaf\": randint(1, 9),\n","    \"criterion\": [\"gini\", \"entropy\"]\n","}\n","\n","tree = DecisionTreeClassifier()\n","tree_cv = RandomizedSearchCV(tree, param_dist, cv=5)\n","tree_cv.fit(X, y)\n","\n","print(\"Tuned Decision Tree Parameters: {}\".format(tree_cv.best_params_))\n","print(\"Best score is {}\".format(tree_cv.best_score_))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"o6qWYY0AeLDT","executionInfo":{"status":"ok","timestamp":1770292726727,"user_tz":-420,"elapsed":472,"user":{"displayName":"RD Prastowo","userId":"02625078348602365406"}},"outputId":"75811906-35f5-411a-85db-513af4038891"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Tuned Decision Tree Parameters: {'criterion': 'entropy', 'max_depth': None, 'max_features': 7, 'min_samples_leaf': 1}\n","Best score is 0.8400000000000001\n"]}]}]}